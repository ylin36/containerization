# 1. Deployment

Deployments create replicasets which in term create pods
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-demo-2-db
spec:
  selector:
    matchLabels:
      type: db
      service: go-demo-2
  template:
    metadata:
      labels:
        type: db
        service: go-demo-2
        vendor: MongoLabs
    spec:
      containers:
      - name: db
        image: mongo:3.3
        ports:
        - containerPort: 28017
```

change image of the deployment yaml. record will record the history
```
kubectl set image \
    -f deploy/go-demo-2-db.yml \
    db=mongo:3.4 \
    --record
```

# 2. How deployment detect change
```
A value is generated by hashing the PodTemplate of the ReplicaSet. As long as the PodTemplate is the same, the hash value will be the same as well. That way a Deployment can know whether anything related to the Pods has changed and, if it does, will create a new ReplicaSet.
 ```

# 3. Ways to update deployment
## 3.1 Set image (good for CI/CD)
The kubectl set image is more useful if we’d like to integrate Deployment updates with one of the CI/CD tools.
```
kubectl set image \
    -f deploy/go-demo-2-db.yml \
    db=mongo:3.4 \
    --record
```

## 3.2 Edit image (not a good way at all. don't use this)
```
kubectl edit -f deploy/go-demo-2-db.yml
```

# 4. Defining zero downtime deployment

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-demo-2-api
spec:
  replicas: 3
  selector:
    matchLabels:
      type: api
      service: go-demo-2
  minReadySeconds: 1               # minimum number of seconds before k8s starts considering the pod is healthy
  progressDeadlineSeconds: 60      
  revisionHistoryLimit: 5          # number of old ReplicaSet we can rollback. (Default is 10)
  strategy:
    type: RollingUpdate            # can be set to rolling update OR Recreate (kill all existing pod before update)
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:
    metadata:
      labels:
        type: api
        service: go-demo-2
        language: go
    spec:
      containers:
      - name: api
        image: vfarcic/go-demo-2
        env:
        - name: DB
          value: go-demo-2-db
        readinessProbe:
          httpGet:
            path: /demo/hello
            port: 8080
          periodSeconds: 1
        livenessProbe:
          httpGet:
            path: /demo/hello
            port: 8080
```
## 4.1 Recreate strategy
```
If we’re running the database as a single replica, we must have mounted a network drive volume. That would allow us to avoid data loss when updating it or in case of a failure. Since most databases (MongoDB included) cannot have multiple instances writing to the same data files, killing the old release before creating a new one is a good strategy when replication is absent. We’ll apply it later.
```

## 4.2 Rolling update strategy
```
It allows us to deploy new releases without downtime. It creates a new ReplicaSet with zero replicas and, depending on other parameters, increases the replicas of the new one, and decreases those from the old one. The process is finished when the replicas of the new ReplicaSet entirely replace those from the old one.
```

### 4.2.1 maxSurge (default 25%)
defines the maximum number of Pods that can exceed the desired number (set using replicas). It can be set to an absolute number (e.g., 2) or a percentage (e.g., 35%). The total number of Pods will never exceed the desired number (set using replicas) and the maxSurge combined. 
### 4.2.2 maxUnavailable (default 25%)
defines the maximum number of Pods that are not operational. If, for example, the number of replicas is set to 15 and this field is set to 4, the minimum number of Pods that would run at any given moment would be 11.

## 4.3 view rollout status
```
kubectl rollout status -w \
    -f deploy/go-demo-2-api.yml
```

## 4.4 Rolling back or Rolling forward

### 4.4.1 Rolling back (Discouraged)
With continuous deployment it might be faster to just deploy another bug fix since work releases in smaller chunks, so the scope to fix it is lower.

Rolling back a release that introduced database changes is often not possible. Even when it is, rolling forward is usually a better option when practicing continuous deployment with high-frequency releases limited to a small scope of changes.


```
kubectl rollout undo -f deploy/go-demo-2-api.yml

# look at the status of the rollback
kubectl describe -f deploy/go-demo-2-api.yml

# look at the history of the rollout
kubectl rollout history -f deploy/go-demo-2-api.yml
```
Since new deployments do no destroy ReplicaSets but scale them to 0, all it had to do to undo the last change was to scale it back to the desired number of replicas and, at the same time, scale the current one to zero.

### 4.4.2 Update based on selectors
```
kubectl set image deployments \
    -l type=db,vendor=MongoLabs \
    db=mongo:3.4 --record
```

# 5. Scaling
When scaling is frequent and, hopefully, automated, we cannot expect to update YAML definitions and push them to Git. That would be too inefficient and would probably cause quite a few unwanted executions of delivery pipelines if they are triggered through repository WebHooks. After all, do we really want to push updated YAML files multiple times a day?

## 5.1 scaling with scale command
```
kubectl apply \
    -f deploy/go-demo-2-scaled.yml

kubectl get \
    -f deploy/go-demo-2-scaled.yml

...
NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/go-demo-2-api   5/5     5            5           3h26m
...    
```

```
kubectl scale deployment \
    go-demo-2-api --replicas 8 --record

kubectl get -f deploy/go-demo-2.yml

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/go-demo-2-db   1/1     1            1           4h40m

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/go-demo-2-api   8/8     8            8           3h28m
```